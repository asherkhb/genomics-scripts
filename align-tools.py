__author__ = 'asherkhb'
# alignment-tools.py
#
# A collection of quick and dirty tools for doing miscellaneous things to/with MSAs
# '*' Indicate poor-quality, basically useless scripts
#
# Includes
#   - fasta_align_to_list
#   - condenser*
#   - identity_calculator
#   - generate_similarity_tsv
#   - generate_site-identity_tsv

from sys import argv

def fasta_alignment_to_list(alignment_file):
    """FASTA-format MSA to List
    Converts multiple sequence alignments (in FASTA format) to lists.
    Generates file with single-line sequences,

    Returns a list of lists of sequences.

    :param alignment_file:
    """
    sequences = []

    with open(alignment_file, 'r') as alignment, open('temp-align-out.txt', 'w') as otpt:
        reading = True
        first = True
        while reading:
            line = alignment.readline()
            if line == '':
                reading = False
            elif line[0] == '>':
                if first:
                    otpt.write(line)
                    first = False
                else:
                    otpt.write('\n' + line)
            else:
                line = line.strip('\n')
                otpt.write(line)

    with open('temp-align-out.txt', 'r') as aligned_seq:
        reading = True
        while reading:
            line = aligned_seq.readline()
            if line == '':
                reading = False
            elif line[0] == '>':
                pass
            else:
                line = line.strip('\n')
                sequences.append(line)

    #for sequence in sequences:
    #    print sequence
    #    print len(sequence)

    return sequences

def condenser(alignment_file, lines):
    """MSA Condenser

    Not a good script, very fussy.
    Condenses MSA into single-lines and returns scored.
    Will be redone (eventually)

    :param alignment_file:
    :param lines: Number of lines that make up each iteration of alignment
    :return: Scores (* indicating 100% seq. identity output by MUSCLE)
    """
    with open(alignment_file, 'r') as inpt, open('condensed-alignment.txt', 'w') as otpt:
        sequences = []
        for i in range(0, lines-1):
            sequences.append([])

        reading = True
        line_counter = 0
        while reading:
            line = inpt.readline()
            if line == '':
                reading = False
            elif line == '\n':
                pass
            else:
                line = line.strip('\n')
                sequences[line_counter].append(line)
                line_counter += 1
                if line_counter == lines-1:
                    line_counter = 0

        for i in range(0, len(sequences)):
            entry = ''.join(sequences[i])
            otpt.write(entry + '\n')
            #print len(entry)
            if i == len(sequences) - 1:
                scores = entry

    return scores


def generate_similarity_tsv(scores):
    """Similarity TSV Generator

    From a string of identity values (as generated by MUSCLE - * indicate 100% identity).
    Generate a TSV of site locations & identity conservation.
    Only functions to generate report for 100% similarity.
    For specific percentages, use "generate_site_identity_tsv"

    :param scores: String of identity values for a MSA.
    """
    seq_len = len(scores)
    with open('similarity-chart.tsv', 'w') as otpt:
        otpt.write('Site\t% Identity\n')
        for i in range (0, seq_len):
            site = i + 1
            if scores[i] == ' ':
                score = 0
            elif scores[i] == '*':
                score = 1
            entry = '%d\t%d\n' % (site, score)
            otpt.write(entry)


def generate_site_identity_tsv(scores):
    """Percent Site Identity TSV Generator

    From a string of identity values (Typically generated with identity_calculator).
    Generate a TSV of site locations & percent identity at site.

    :param scores: String of identity values for a MSA, usually from identity_calculator.
    """
    seq_len = len(scores)
    with open('site-identity-chart.tsv', 'w') as otpt:
        otpt.write('Site\t% Identity\n')
        for i in range (0, seq_len):
            site = i + 1
            score = scores[i]
            entry = '%d\t%f\n' % (site, score)
            otpt.write(entry)

def identity_calculator(alignment_file):
    """Percent Site Identity Calculator

    From a MSA (only sequence data - single line per sequence, no species names, sequences same length)
    Generate a list of conservation percentages for each site.

    :param alignment_file: MSA file, must contain only sequence data (no species names) and sequences same length
    :return: List of %identity scores for each site in MSA.
    """
    from operator import itemgetter

    #Establish global variables
    sequences = []
    scores = []
    sequence_count = 0

    #Build a list with sequences from alignment file
    with open(alignment_file, 'r') as inpt:
        reading = True
        while reading:
            seq = inpt.readline()
            if seq == '':
                reading = False
            elif seq == '\n':
                pass
            else:
                seq = seq.strip('\n')
                sequences.append(seq)
                sequence_count += 1

    #Calculates length of sequences
    sequence_length = len(sequences[0])

    #Calculates percent identity at each site in the sequences
    #Iterate through each site
    for i in range(0, sequence_length):
        #Establish a dictionary of the bases
        occurances = {'A': 0, 'T': 0, 'G': 0, 'C': 0}

        #Establish an empty list for holding value of each site
        comp_list = []

        #Add each sequence site to comparison list
        for sequence in sequences:
            comp_list.append(sequence[i])

        #Modify occurances dictioanry with number of times each base occurs
        for entry in comp_list:
            if entry in occurances:
                occurances[entry] += 1

        #Calculate the most frequent base
        most_freq_base = max(occurances.iteritems(), key=itemgetter(1))[0]

        #Calculate how conserved most frequent base is over alignment
        percent_identity = float(occurances[most_freq_base]) / sequence_count

        #Add score for site to scores list
        scores.append(percent_identity)

    #Return a list of site %identity scores
    return scores

generate_site_identity_tsv(identity_calculator(argv[1]))